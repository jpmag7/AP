{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## **CNN para classificação (binária) multiclasse de imagens**\n",
    "**Dataset Fashion-MNIST**\n",
    "- Dataset de imagens de peças de vestuário\n",
    "- Imagens de 28x28 pixeis\n",
    "- 70k imagens das quais 60k são para treino e 10k para teste\n",
    "- 10 classes e 785 atributos (o 1º é a classe a classificar o tipo de vestuário e as restantes são valores dos pixéis das imagens)\n",
    "- Classes: T-shirt/top, Trouser, Pullover, Dress, Coat, Sandal, Shirt, Sneaker, Bag e Ankle boot\n",
    "    \n",
    "Vamos utilizar uma rede neuronal para classificação do dígito em cada imagem de 28x28."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "from torch.nn import BatchNorm2d\n",
    "from torch.nn import Dropout2d\n",
    "from torch.nn import Sequential\n",
    "from torch.nn import Linear\n",
    "from torch.nn import Conv2d\n",
    "from torch.nn import MaxPool2d\n",
    "from torch.nn import ReLU\n",
    "from torch.nn import Softmax\n",
    "from torch.nn import Module\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import SGD, Adam\n",
    "from torch.nn.init import kaiming_uniform_\n",
    "from torch.nn.init import xavier_uniform_\n",
    " \n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import Compose\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.transforms import Normalize\n",
    "from torchinfo import summary\n",
    "\n",
    "from livelossplot import PlotLosses\n",
    "\n",
    "np.random.seed(0) \n",
    "torch.manual_seed(0)\n",
    "import random\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './'\n",
    "PATH_TRAIN = './fashion-mnist_train.csv'\n",
    "PATH_TEST = './fashion-mnist_test.csv'\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def get_default_device():\n",
    "    ...\n",
    "\n",
    "def to_device(data, device):\n",
    "    ...\n",
    "\n",
    "class DeviceDataLoader():\n",
    "    ...\n",
    "        \n",
    "    def __iter__(self):\n",
    "        ...\n",
    "\n",
    "    def __len__(self):\n",
    "        ...\n",
    "\n",
    "device = get_default_device()\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Preparar os Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = Compose(\n",
    "        [ToTensor(), \n",
    "         Normalize(mean=(0.1307,), std=(0.3081,)) \n",
    "        ])\n",
    "test_transform = Compose(\n",
    "        [ToTensor(), \n",
    "         Normalize(mean=(0.1307,), std=(0.3081,))\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CSVDataset(Dataset):\n",
    "    def __init__(self, path, transform=None):\n",
    "        ...\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        ...\n",
    "    \n",
    "    def get_TensorDataset(self):\n",
    "        ...\n",
    "\n",
    "def prepare_data_loaders(path_train, path_test):\n",
    "    ...\n",
    "\n",
    "train_dl, val_dl, test_dl, train_dl_all, val_dl_all, test_dl_all = prepare_data_loaders(PATH_TRAIN, PATH_TEST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1.1 Visualizar os Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_label(label):\n",
    "    output_mapping = { 0: \"T-shirt/Top\", 1: \"Trouser\", 2: \"Pullover\",\n",
    "                       3: \"Dress\",       4: \"Coat\",    5: \"Sandal\", \n",
    "                       6: \"Shirt\",       7: \"Sneaker\", 8: \"Bag\", \n",
    "                       9: \"Ankle Boot\" }\n",
    "    output_mapping2 = { 0: \"0\", 1: \"1\", 2: \"2\", 3: \"3\", 4: \"4\", \n",
    "                       5: \"5\", 6: \"6\", 7: \"7\", 8: \"8\", 9: \"9\"}\n",
    "    input = (label.item() if type(label) == torch.Tensor else label)\n",
    "    return output_mapping[input]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "def visualize_data(path):\n",
    "    ...\n",
    "\n",
    "def visualize_dataset(train_dl, test_dl):\n",
    "    ...\n",
    "\n",
    "visualize_data(PATH_TRAIN)\n",
    "visualize_dataset(train_dl, test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def visualize_images(dl):\n",
    "    ...\n",
    "\n",
    "visualize_images(train_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1.2 Verificar balanceamento do dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_holdout_balance(dl, titulo):\n",
    "    ... \n",
    "\n",
    "print(\"-----------------------------------casos_treino-----------------------------------\")   \n",
    "visualize_holdout_balance(train_dl_all, 'Treino')\n",
    "print(\"-----------------------------------casos_validação-----------------------------------\")   \n",
    "visualize_holdout_balance(val_dl_all, 'Validação')\n",
    "print(\"-----------------------------------casos_teste-----------------------------------\") \n",
    "visualize_holdout_balance(test_dl_all, 'Teste')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. Definir o Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel_1(Module):\n",
    "    ...\n",
    "\n",
    "model = CNNModel_1()\n",
    "print(summary(model, input_size=(BATCH_SIZE, 1,28,28), verbose=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel_2(Module):\n",
    "    ...\n",
    "    \n",
    "#model = CNNModel_2()\n",
    "#print(summary(model, input_size=(BATCH_SIZE, 1,28,28), verbose=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel_3(Module):\n",
    "    ...\n",
    "    \n",
    "#model = CNNModel_3()\n",
    "#print(summary(model, input_size=(BATCH_SIZE, 1,28,28), verbose=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel_4(Module):\n",
    "    ...\n",
    "    \n",
    "#model = CNNModel_4()\n",
    "#print(summary(model, input_size=(BATCH_SIZE, 1,28,28), verbose=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3. Treinar o Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(h5_file, train_dl, val_dl, model, criterion, optimizer):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### CNNModel_1 ################\n",
    "model = CNNModel_1()\n",
    "print(summary(model, input_size=(BATCH_SIZE, 1,28,28), verbose=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### CNNModel_2 ################\n",
    "#model = CNNModel_2()\n",
    "#print(summary(model, input_size=(BATCH_SIZE, 1,28,28), verbose=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### CNNModel_3 ################\n",
    "#model = CNNModel_3()\n",
    "#print(summary(model, input_size=(BATCH_SIZE, 1,28,28), verbose=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "######### CNNModel_4 ################\n",
    "#model = CNNModel_4()\n",
    "#print(summary(model, input_size=(BATCH_SIZE, 1,28,28), verbose=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4. Avaliar o Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_model(test_dl, model):\n",
    "    ...s\n",
    "\n",
    "def display_predictions(actual_values, predictions ):\n",
    "    ...\n",
    "    \n",
    "def display_confusion_matrix(cm,list_classes):\n",
    "    ... \n",
    "    \n",
    "actual_values, predictions = evaluate_model(test_dl_all, model)\n",
    "display_predictions(actual_values, predictions )\n",
    "print(classification_report(actual_values, predictions))\n",
    "cr =classification_report(actual_values, predictions, output_dict=True)\n",
    "list_classes=[output_label(n) for n in list(cr.keys())[0:10] ] \n",
    "cm = confusion_matrix(actual_values, predictions)\n",
    "\n",
    "print (cm)\n",
    "display_confusion_matrix(cm,list_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 5. Usar o Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediction(model, img):\n",
    "    ...\n",
    "\n",
    "model= torch.load('CNNModel_1.pth')\n",
    "imagens, label = next(iter(test_dl))\n",
    "make_prediction(model,imagens[3])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
