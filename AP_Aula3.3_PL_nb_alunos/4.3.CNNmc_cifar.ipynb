{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## **CNN para classificação multiclasse de imagens**\n",
    "**Dataset CIFAR-10 (Canadian Institute For Advanced Research)**\n",
    "- Dataset de imagens\n",
    "- 60k imagens de cor com 32x32 pixeis classificadas em 10 classes diferentes\n",
    "- Classes: aviões, carros, aves, gatos, veados, rãs, cavalos, navios e camiões\n",
    "- 6k por cada classe\n",
    "- 5k imagens são usadas para treino e 1k para teste\n",
    "\n",
    "Vamos utilizar uma rede neuronal convolucional para classificação das imagens numa das classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "from torch.nn import BatchNorm2d\n",
    "from torch.nn import Dropout2d\n",
    "from torch.nn import Sequential\n",
    "from torch.nn import Linear\n",
    "from torch.nn import Conv2d\n",
    "from torch.nn import MaxPool2d\n",
    "from torch.nn import ReLU\n",
    "from torch.nn import Softmax\n",
    "from torch.nn import Module\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import SGD, Adam\n",
    "from torch.nn.init import kaiming_uniform_\n",
    "from torch.nn.init import xavier_uniform_\n",
    " \n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import Compose\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.transforms import Normalize\n",
    "from torchinfo import summary\n",
    "\n",
    "from livelossplot import PlotLosses\n",
    "\n",
    "np.random.seed(0) \n",
    "torch.manual_seed(0)\n",
    "import random\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparar o setup\n",
    "Irá ser criada uma estrutura de diretorias em que em [train] temos as images para treino e em [test] as imagens para teste.\n",
    "O ficheiro \"labels.txt\" tem as classes enumeradas. A classe a que cada imagem pertence está no nome do ficheiro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './cifar/'\n",
    "PATH_CLASSES = './cifar/labels.txt'\n",
    "PATH_TRAIN = './cifar/train'\n",
    "PATH_TEST = './cifar/test'\n",
    "\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def get_default_device():\n",
    "    ...\n",
    "\n",
    "def to_device(data, device):\n",
    "    ...\n",
    "\n",
    "class DeviceDataLoader():\n",
    "    ...\n",
    "        \n",
    "    def __iter__(self):\n",
    "        ...\n",
    "\n",
    "    def __len__(self):\n",
    "        ...\n",
    "\n",
    "device = get_default_device()\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Preparar os Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classes(path):\n",
    "    with open(\"cifar/labels.txt\") as fich_labels:\n",
    "        labels = fich_labels.read().split()\n",
    "        classes = dict(zip(labels, list(range(len(labels)))))\n",
    "    return classes\n",
    "...)\n",
    "print(dic_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocessar(imagem):\n",
    "    imagem = np.array(imagem)\n",
    "    cifar_mean = np.array([0.4914, 0.4822, 0.4465]).reshape(1,1,-1)\n",
    "    cifar_std  = np.array([0.2023, 0.1994, 0.2010]).reshape(1,1,-1)\n",
    "    imagem = (imagem - cifar_mean) / cifar_std\n",
    "    xmax, xmin = imagem.max(), imagem.min()\n",
    "    imagem = (imagem - xmin)/(xmax - xmin)\n",
    "    imagem = imagem.transpose(2,1,0)\n",
    "    ...\n",
    "\n",
    "class Cifar10Dataset(Dataset):\n",
    "\n",
    "    def __init__(self, path, mun_imagens = 0, transforms=None):\n",
    "        files = os.listdir(path)\n",
    "        files = [os.path.join(path,f) for f in files]\n",
    "        if mun_imagens == 0:\n",
    "            mun_imagens = len(files)\n",
    "        self.mun_imagens = mun_imagens\n",
    "        self.files = random.sample(files, self.mun_imagens)\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.mun_imagens\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        fich_imagem = self.files[idx]\n",
    "        imagem = Image.open(fich_imagem)\n",
    "        imagem = preprocessar(imagem)\n",
    "        label_classe = fich_imagem[:-4].split(\"_\")[-1]\n",
    "        label = dic_classes[label_classe]\n",
    "        imagem = imagem.astype(np.float32)\n",
    "        if self.transforms:\n",
    "            imagem = self.transforms(imagem)\n",
    "        ...\n",
    "\n",
    "def prepare_data_loaders(path_train, path_test):\n",
    "    dataset_train = Cifar10Dataset(path_train,transforms=None)\n",
    "    dataset_test = Cifar10Dataset(path_test,transforms=None)\n",
    "    \n",
    "    train_size = int(0.8 * len(dataset_train))\n",
    "    val_size = len(dataset_train) - train_size\n",
    "    train, validation = random_split(dataset_train, [train_size, val_size], generator=torch.Generator().manual_seed(42))\n",
    "    \n",
    "    train_dl = DataLoader(train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_dl = DataLoader(validation, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    test_dl = DataLoader(dataset_test, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    train_dl_all = DataLoader(train, batch_size=len(train), shuffle=True)\n",
    "    val_dl_all = DataLoader(validation, batch_size=len(validation), shuffle=True)\n",
    "    test_dl_all = DataLoader(dataset_test, batch_size=len(dataset_test), shuffle=True)\n",
    "    return train_dl, val_dl, test_dl, train_dl_all, val_dl_all, test_dl_all\n",
    "\n",
    "train_dl, val_dl, test_dl, train_dl_all, val_dl_all, test_dl_all = prepare_data_loaders(PATH_TRAIN, PATH_TEST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1.1 Visualizar os Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_label(label,mapping='label'):\n",
    "    if mapping == 'ext':\n",
    "        output_mapping = { 0:\"zero\", 1:\"um\", 2:\"dois\", 3:\"tres\", 4:\"quatro\", 5:\"cinco\", 6:\"seis\", 7:\"sete\", 8:\"oito\", 9:\"nove\" }\n",
    "    elif mapping == 'ext2':\n",
    "        output_mapping = { \"0\":\"zero\", \"1\":\"um\", \"2\":\"dois\", \"3\":\"tres\", \"4\":\"quatro\", \"5\":\"cinco\", \"6\":\"seis\", \"7\":\"sete\", \"8\":\"oito\", \"9\":\"nove\" }\n",
    "    else:\n",
    "        output_mapping = { 0: \"0\", 1: \"1\", 2: \"2\", 3: \"3\", 4: \"4\", 5: \"5\", 6: \"6\", 7: \"7\", 8: \"8\", 9: \"9\"}\n",
    "    input = (label.item() if type(label) == torch.Tensor else label)\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "...\n",
    "\n",
    "def visualize_data(path):\n",
    "    df = pd.read_csv(path, header=0)\n",
    "    display(df)\n",
    "\n",
    "def visualize_dataset(train_dl, test_dl, dataset_train, dataset_test):\n",
    "    print(f\"Quantidade de casos de Treino:{len(train_dl.dataset)}\") \n",
    "    print(f\"Quantidade de casos de Validação:{len(val_dl.dataset)}\")\n",
    "    print(f\"Quantidade de casos de Teste:{len(test_dl.dataset)}\")\n",
    "    \n",
    "    x, y = next(iter(train_dl))\n",
    "    print(f\"Shape tensor batch casos treino, input: {x.shape}, output: {y.shape}\")\n",
    "    x, y = next(iter(val_dl))\n",
    "    print(f\"Shape tensor batch casos validação, input: {x.shape}, output: {y.shape}\")\n",
    "    x, y = next(iter(test_dl))  \n",
    "    print(f\"Shape tensor batch casos test, input: {x.shape}, output: {y.shape}\")\n",
    "    \n",
    "    print(f'Valor maximo:{torch.max(x)} Valor mínimo:{torch.min(x)}')\n",
    "    x=x.detach().numpy()\n",
    "    print(f'Valor maximo:{np.max(x)} Valor mínimo:{np.min(x)}')\n",
    "    print(y)\n",
    "    \n",
    "visualize_dataset(train_dl, test_dl, train_dl_all, test_dl_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def visualize_images(dl):\n",
    "    i, (inputs, targets) = next(enumerate(dl))\n",
    "    print(inputs.shape)\n",
    "    plt.figure(figsize=(8,8))\n",
    "    for i in range(25):\n",
    "        plt.subplot(5, 5, i+1)\n",
    "        plt.axis('off')\n",
    "        plt.grid(b=None)\n",
    "        imagem = inputs[i]\n",
    "        plt.imshow(imagem.permute((2, 1, 0)))\n",
    "    plt.show()\n",
    "\n",
    "visualize_images(train_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1.2 Verificar balanceamento do dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "...\n",
    "\n",
    "def visualize_holdout_balance(dl, titulo):\n",
    "    _, labels = next(iter(dl))                            \n",
    "    sns.set_style('whitegrid')\n",
    "    print(\"casos:\",len(labels))\n",
    "    x, y = np.unique(labels, return_counts=True)\n",
    "    x_ext=[list(dic_classes.keys())[n] for n in x]\n",
    "    print([str(n)  for n in x])\n",
    "    print(y)\n",
    "    print(np.sum(y))\n",
    "    grafico=sns.barplot(x_ext, y)\n",
    "    grafico.set_title(f'Data balance: {titulo}')\n",
    "    plt.xticks(rotation=70)\n",
    "    plt.tight_layout()\n",
    "    plt.show() \n",
    "    \n",
    "print(\"-----------------------------------casos_treino-----------------------------------\")   \n",
    "visualize_holdout_balance(train_dl_all, 'Treino')\n",
    "print(\"-----------------------------------casos_validação-----------------------------------\")   \n",
    "visualize_holdout_balance(val_dl_all, 'Validação')\n",
    "print(\"-----------------------------------casos_teste-----------------------------------\") \n",
    "visualize_holdout_balance(test_dl_all, 'Teste')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. Definir o Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=out_channels,kernel_size=(3, 3), stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_channels=out_channels, out_channels=out_channels,kernel_size=(3, 3), stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "    \n",
    "        ...\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=in_channels, out_channels=out_channels,kernel_size=(1, 1), stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = nn.ReLU()(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = nn.ReLU()(out)\n",
    "        ...\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=(3, 3),stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.block1 = self._create_block(64, 64, stride=1)\n",
    "        self.block2 = self._create_block(64, 128, stride=2)\n",
    "        self.block3 = self._create_block(128, 256, stride=2)\n",
    "        self.block4 = self._create_block(256, 512, stride=2)\n",
    "        self.linear = nn.Linear(512, num_classes)\n",
    "\n",
    "    def _create_block(self, in_channels, out_channels, stride):\n",
    "        return nn.Sequential(\n",
    "            ResidualBlock(in_channels, out_channels, stride),\n",
    "            ResidualBlock(out_channels, out_channels, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = nn.ReLU()(self.bn1(self.conv1(x)))\n",
    "        out = self.block1(out)\n",
    "        out = self.block2(out)\n",
    "        out = self.block3(out)\n",
    "        out = self.block4(out)\n",
    "        out = nn.AvgPool2d(4)(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "    \n",
    "...\n",
    "print(summary(model, input_size=(BATCH_SIZE, 3,32,32), verbose=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel_1(Module):\n",
    "    ...\n",
    "\n",
    "#model = CNNModel_1()\n",
    "#print(summary(model, input_size=(BATCH_SIZE, 3,32,32), verbose=0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel_2(Module):\n",
    "    ...\n",
    "    \n",
    "#model = CNNModel_2()\n",
    "#print(summary(model, input_size=(BATCH_SIZE, 3,32,32), verbose=0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel_3(Module):\n",
    "    ...\n",
    "    \n",
    "#model = CNNModel_3()\n",
    "#print(summary(model, input_size=(BATCH_SIZE, 3,32,32), verbose=0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel_4(Module):\n",
    "    ...\n",
    "    \n",
    "#model = CNNModel_4()\n",
    "#print(summary(model, input_size=(BATCH_SIZE, 3,32,32), verbose=0)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3. Treinar o Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(h5_file, train_dl, val_dl, model, criterion, optimizer):\n",
    "    liveloss = PlotLosses()\n",
    "    for epoch in range(EPOCHS):\n",
    "        logs = {}\n",
    "        model.train() \n",
    "        running_loss  = 0.0\n",
    "        running_corrects  = 0.0\n",
    "        for batch_i, (inputs, labels) in enumerate(train_dl): \n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.detach() * inputs.size(0)\n",
    "            _, preds = torch.max(outputs, 1) \n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "        epoch_loss = running_loss / len(train_dl.dataset)\n",
    "        epoch_acc = running_corrects.float() / len(train_dl.dataset)\n",
    "        logs['loss'] = epoch_loss.item()\n",
    "        logs['accuracy'] = epoch_acc.item()\n",
    "            \n",
    "        model.eval()\n",
    "        running_loss  = 0.0\n",
    "        running_corrects  = 0.0\n",
    "        for inputs, labels in val_dl: \n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.detach() * inputs.size(0)\n",
    "            _, preds = torch.max(outputs, 1) \n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "        epoch_loss = running_loss / len(val_dl.dataset)\n",
    "        epoch_acc = running_corrects.float() / len(val_dl.dataset)\n",
    "        logs['val_loss'] = epoch_loss.item()\n",
    "        logs['val_accuracy'] = epoch_acc.item()     \n",
    "        liveloss.update(logs)\n",
    "        liveloss.send()\n",
    "    torch.save(model,h5_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "######### ResNet ################\n",
    "...\n",
    "print(summary(model, input_size=(BATCH_SIZE, 3,32,32), verbose=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 30\n",
    "LEARNING_RATE = 0.001\n",
    "criterion = CrossEntropyLoss()\n",
    "optimizer = SGD(model.parameters(), lr=LEARNING_RATE) \n",
    "starttime = time.perf_counter()\n",
    "train_model('CNNModel_cifar_Resnet.pth', train_dl, val_dl, model, criterion, optimizer)\n",
    "endtime = time.perf_counter()\n",
    "print(f\"Tempo gasto: {endtime - starttime} segundos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### CNNModel_1 ################\n",
    "...\n",
    "print(summary(model, input_size=(BATCH_SIZE, 3,32,32), verbose=0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "...\n",
    "train_model('CNNModel_cifar_1.pth', train_dl, val_dl, model, criterion, optimizer)\n",
    "endtime = time.perf_counter()\n",
    "print(f\"Tempo gasto: {endtime - starttime} segundos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### CNNModel_2 ################\n",
    "...\n",
    "print(summary(model, input_size=(BATCH_SIZE, 3,32,32), verbose=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "...\n",
    "train_model('CNNModel_cifar_2.pth', train_dl, val_dl, model, criterion, optimizer)\n",
    "endtime = time.perf_counter()\n",
    "print(f\"Tempo gasto: {endtime - starttime} segundos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### CNNModel_3 ################\n",
    "...\n",
    "print(summary(model, input_size=(BATCH_SIZE, 3,32,32), verbose=0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "...\n",
    "train_model('CNNModel_cifar_3.pth', train_dl, val_dl, model, criterion, optimizer)\n",
    "endtime = time.perf_counter()\n",
    "print(f\"Tempo gasto: {endtime - starttime} segundos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "######### CNNModel_4 ################\n",
    "...\n",
    "print(summary(model, input_size=(BATCH_SIZE, 3,32,32), verbose=0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "...\n",
    "train_model('CNNModel_cifar_4.pth', train_dl, val_dl, model, criterion, optimizer)\n",
    "endtime = time.perf_counter()\n",
    "print(f\"Tempo gasto: {endtime - starttime} segundos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4. Avaliar o Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_model(test_dl, model):\n",
    "    predictions = list()\n",
    "    actual_values = list()\n",
    "    for inputs, labels in test_dl:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        yprev = model(inputs)\n",
    "        yprev = yprev.detach().cpu().numpy()\n",
    "        actual = labels.cpu().numpy()\n",
    "        yprev = np.argmax(yprev, axis=1)\n",
    "        actual = actual.reshape((len(actual), 1))\n",
    "        yprev = yprev.reshape((len(yprev), 1))\n",
    "        predictions.append(yprev)\n",
    "        actual_values.append(actual)\n",
    "        break\n",
    "    predictions, actual_values = np.vstack(predictions), np.vstack(actual_values)\n",
    "    return actual_values, predictions\n",
    "\n",
    "def display_predictions(actual_values, predictions ):\n",
    "    acertou=0\n",
    "    falhou = 0\n",
    "    primeiros=0\n",
    "    for r,p in zip(actual_values, predictions):\n",
    "        if primeiros <20:\n",
    "            print(f'real:{r} previsão:{p}') \n",
    "            primeiros +=1\n",
    "        if r==p: acertou+=1  \n",
    "        else: falhou+=1\n",
    "    corrects = np.sum(predictions == actual_values)\n",
    "    acc = corrects / len(test_dl.dataset)\n",
    "    acc = accuracy_score(actual_values, predictions)\n",
    "    print(f'Accuracy: {acc:0.3f}\\n')\n",
    "    print(f'acertou:{acertou} falhou:{falhou}')\n",
    "\n",
    "    acc = accuracy_score(actual_values, predictions)\n",
    "    print(f'Accuracy: {acc:0.3f}\\n')\n",
    "    print(f'acertou:{acertou} falhou:{falhou}')\n",
    "\n",
    "def display_confusion_matrix(cm,list_classes):\n",
    "    plt.figure(figsize = (16,8))\n",
    "    sns.heatmap(cm,annot=True,xticklabels=list_classes,yticklabels=list_classes, annot_kws={\"size\": 12}, fmt='g', linewidths=.5)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show() \n",
    "    \n",
    "...\n",
    "actual_values, predictions = evaluate_model(test_dl_all, model)\n",
    "display_predictions(actual_values, predictions )\n",
    "print(classification_report(actual_values, predictions))\n",
    "cr =classification_report(actual_values, predictions, output_dict=True)\n",
    "list_classes=[output_label(n,'ext2') for n in list(cr.keys())[0:10] ] \n",
    "cm = confusion_matrix(actual_values, predictions)\n",
    "\n",
    "print (cm)\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 5. Usar o Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediction(model, img): \n",
    "    ...\n",
    "\n",
    "...\n",
    "imagens, label = next(iter(test_dl))\n",
    "make_prediction(model,imagens[3]) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
