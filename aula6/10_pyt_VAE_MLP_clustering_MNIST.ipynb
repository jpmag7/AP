{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Clustering utilizando modelos Autoencoder e Variational Autoencoder treinados com o MNIST\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image_info](https://www.researchgate.net/profile/Xifeng-Guo/publication/320658590/figure/fig1/AS:614154637418504@1523437284408/The-structure-of-proposed-Convolutional-AutoEncoders-CAE-for-MNIST-In-the-middle-there_W640.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch conv for binary classification\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import image\n",
    "\n",
    "import torch\n",
    "\n",
    "from torch import Tensor\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "    \n",
    "from torchvision.transforms import Compose\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.utils import save_image, make_grid\n",
    "\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Constants\n",
    "\n",
    "#path para guardar o dataset\n",
    "PATH = './'\n",
    "PATH_TRAIN = './mnist_train.csv'\n",
    "PATH_TEST = './mnist_test.csv'\n",
    "\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#device management \n",
    "\n",
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "\n",
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "class DeviceDataLoader():\n",
    "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dl: \n",
    "            yield to_device(b, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches\"\"\"\n",
    "        return len(self.dl)\n",
    "\n",
    "device = get_default_device()\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Preparar os Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#buscar o dataset utilizando os CSVs e uma classe para o dataset\n",
    "\n",
    "# definição classe para o dataset\n",
    "class CSVDataset(Dataset):\n",
    "    # ler o dataset\n",
    "    def __init__(self, path_train, path_test):\n",
    "        # ler o ficheiro csv para um dataframe\n",
    "        df_train = pd.read_csv(path_train, header=0)\n",
    "        df_test = pd.read_csv(path_test, header=0)\n",
    "        # separar os inputs e os outputs\n",
    "        self.x_train = df_train.values[:, 1:]\n",
    "        self.x_train = self.x_train.reshape(len(self.x_train), 1, 28, 28)\n",
    "        xmax, xmin = self.x_train.max(), self.x_train.min()\n",
    "        self.x_train  = (self.x_train - xmin)/(xmax - xmin)\n",
    "        self.y_train = df_train.values[:, 0]\n",
    "        self.x_test = df_test.values[:, 1:]\n",
    "        self.x_test = self.x_test.reshape(len(self.x_test), 1, 28, 28)\n",
    "        xmax, xmin = self.x_test.max(), self.x_test.min()\n",
    "        self.x_test  = (self.x_test - xmin)/(xmax - xmin)\n",
    "        self.y_test = df_test.values[:, 0]\n",
    "        # garantir que os inputs e labels sejam floats\n",
    "        self.x_train = self.x_train.astype('float32')\n",
    "        self.x_test = self.x_test.astype('float32')\n",
    "        self.y_train = self.y_train.astype('long')\n",
    "        self.y_test = self.y_test.astype('long')\n",
    "        \n",
    "    # numero de casos de treino no dataset\n",
    "    def __len_train__(self):\n",
    "        return len(self.x_train)\n",
    "     # numero de casos de teste no dataset\n",
    "    def __len_test__(self):\n",
    "        return len(self.x_test)\n",
    "    \n",
    "    # retornar um caso\n",
    "    def __getitem_train__(self, idx):\n",
    "        return [self.x_train[idx], self.y_train[idx]]\n",
    "     # retornar um caso\n",
    "    def __getitem_test__(self, idx):\n",
    "        return [self.x_test[idx], self.y_test[idx]]\n",
    "    \n",
    "    # retornar indeces para casos de treino de de teste em formato flat (vetor)\n",
    "    def get_splits(self):\n",
    "        x_train  = torch.from_numpy(np.array(self.x_train))\n",
    "        y_train  = torch.from_numpy(np.array(self.y_train))\n",
    "        x_test  = torch.from_numpy(np.array(self.x_test))\n",
    "        y_test  = torch.from_numpy(np.array(self.y_test))\n",
    "        train = torch.utils.data.TensorDataset(x_train,y_train)\n",
    "        test = torch.utils.data.TensorDataset(x_test,y_test)\n",
    "        return train, test \n",
    "    \n",
    "# preparar o dataset\n",
    "def prepare_data_flat(path_train, path_test):\n",
    "    # criar uma instancia do dataset\n",
    "    dataset = CSVDataset(path_train, path_test)\n",
    "    # calcular split\n",
    "    train, test = dataset.get_splits()\n",
    "    # preparar data loaders\n",
    "    train_dl = DataLoader(train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    test_dl = DataLoader(test, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    train_dl_all = DataLoader(train, batch_size=len(train), shuffle=False)\n",
    "    test_dl_all = DataLoader(test, batch_size=len(test), shuffle=False)\n",
    "    return train_dl, test_dl, train_dl_all, test_dl_all\n",
    "\n",
    "# preparar os dados\n",
    "train_dl, test_dl,  train_dl_all, test_dl_all = prepare_data_flat(PATH_TRAIN, PATH_TEST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1.1 Visualizar os Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualização das imagens\n",
    "def visualize_mnist_images_flat(dl):\n",
    "    # get one batch of images\n",
    "    i, (inputs, targets) = next(enumerate(dl))\n",
    "    print(inputs.shape)\n",
    "    print(inputs.shape)\n",
    "    print(inputs.shape)\n",
    "    # plot some images\n",
    "    plt.figure(figsize=(8,8))\n",
    "    for i in range(25):\n",
    "        # define subplot\n",
    "        plt.subplot(5, 5, i+1)\n",
    "        plt.axis('off')\n",
    "        plt.grid(b=None)\n",
    "        # plot raw pixel data\n",
    "        plt.imshow(inputs[i][0], cmap='gray')\n",
    "    # show the figure\n",
    "    ...\n",
    "\n",
    "visualize_mnist_images_flat(test_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. Definir o Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import models_mnist #modulo python com os modelos       \n",
    "\n",
    "model = models_mnist.VAE_MLP(x_dim=784, h_dim1= 512, h_dim2=256, z_dim=2)\n",
    "# ler o modelo\n",
    "SAVED_MODEL = ...\n",
    "model= torch.load(SAVED_MODEL, map_location ='cpu')\n",
    "model.eval()\n",
    "#visualizar a rede\n",
    "print(summary(model, input_size=(BATCH_SIZE, 784), verbose=0))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Usar o Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(input_imgs, ls, output_imgs):\n",
    "    input_imgs=input_imgs.permute((1, 2, 0))\n",
    "    output_imgs=output_imgs.permute((1, 2, 0))\n",
    "    ls=ls.permute((1, 2, 0))\n",
    "    plt.subplots(1,3, figsize=(15, 10))\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.axis('off')\n",
    "    plt.grid(b=None)\n",
    "    plt.title('AE Input')\n",
    "    plt.imshow(input_imgs, cmap='gray')\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.axis('off')\n",
    "    plt.grid(b=None)\n",
    "    plt.title('AE ls')\n",
    "    plt.imshow(ls.detach().numpy() , cmap='gray')\n",
    "    plt.subplot(1,3,3)\n",
    "    plt.axis('off')\n",
    "    plt.grid(b=None)\n",
    "    plt.title('AE output')\n",
    "    plt.imshow(output_imgs, cmap='gray')\n",
    "    plt.show()\n",
    "\n",
    "def test_image_reconstruction(model, test_dl):\n",
    "    for batch in test_dl:\n",
    "        img, _ = batch\n",
    "        img = img.to(device)\n",
    "        print(img.shape)\n",
    "        outputs, ls,_,_ = model(img)\n",
    "        print(f'outputs.shape:{outputs.shape}')\n",
    "        print(f'ls.shape:{ls.shape}')\n",
    "        outputs = outputs.view(outputs.size(0), 1, 28, 28).cpu().data\n",
    "        print(f'outputs.shape:{outputs.shape}')\n",
    "        inputs = img.view(outputs.size(0), 1, 28, 28).cpu().data\n",
    "        outputs = make_grid(outputs)\n",
    "        inputs = make_grid(inputs)\n",
    "        ls = make_grid(ls.cpu())\n",
    "        break \n",
    "    return inputs, outputs, ls\n",
    "\n",
    "inputs, outputs, ls = test_image_reconstruction(model, test_dl)\n",
    "visualize(inputs, ls, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fazer uma previsão utilizando um caso\n",
    "def make_prediction(model, img_list, idx):\n",
    "    print(img_list.shape)\n",
    "    print(img_list.dtype) \n",
    "    img_list = img_list.to(device)\n",
    "    prediction, ls,_,_ = model(img_list)\n",
    "    print(prediction.shape)\n",
    "    prediction = prediction.view(prediction.size(0), 1, 28, 28).cpu().data\n",
    "    print(prediction.shape)\n",
    "    img = img_list[idx].reshape(1,28, 28).cpu()\n",
    "    plt.subplots(1,3, figsize=(15, 10))\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.axis('off')\n",
    "    plt.grid(b=None)\n",
    "    plt.title(...)\n",
    "    plt.imshow(img.permute((1, 2, 0)), cmap='gray')\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.axis('off')\n",
    "    plt.grid(b=None)\n",
    "    plt.title(f'AE ls:{ls.cpu().detach().numpy()[idx]}')\n",
    "    plt.imshow(prediction[idx].permute((1, 2, 0)), cmap='gray')\n",
    "    plt.subplot(1,3,3)\n",
    "    plt.axis('off')\n",
    "    plt.grid(b=None)\n",
    "    plt.title(...)\n",
    "    plt.imshow(prediction[idx].permute((1, 2, 0)), cmap='gray')\n",
    "    plt.show()\n",
    "\n",
    "_, (inputs, targets) = next(enumerate(test_dl))\n",
    "make_prediction(model,inputs, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_t_test(t_test,y_test):\n",
    "    # grafico do latent vector t_test colorido pelos valores dos digitos nas imagens de input\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(t_test[:, 0], t_test[:, 1], marker='x', s=6.0, c=y_test,  cmap='brg')\n",
    "    plt.colorbar();\n",
    "    plt.show()\n",
    "\n",
    "def plot2_t_test(t_test,y_test):   \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(t_test[:, 0], t_test[:, 1],s=0.2, c=y_test, cmap='brg')\n",
    "    plt.colorbar();\n",
    "    count=0;\n",
    "    plt.tight_layout()\n",
    "    plt.suptitle(\"Isomap para digitos do MNIST\")\n",
    "    for label , x, y in zip(y_test, t_test[:, 0], t_test[:, 1]):\n",
    "    #anotar na imagem cada 1 em 300 amostras\n",
    "        if count % 400 == 0:\n",
    "            plt.annotate(str(int(label)),xy=(x,y), color='black', weight='normal',size=10,bbox=dict(boxstyle=\"round4,pad=.5\", fc=\"0.8\"))\n",
    "        count = count + 1\n",
    "    plt.show()\n",
    "     \n",
    "def test_image_clustering(model, test_dl):\n",
    "    for batch in test_dl:\n",
    "        img, labels = batch\n",
    "        img = img.to(device)\n",
    "        print(f'inputs.shape:{img.shape}')\n",
    "        print(f'labes.shape:{labels.shape}')\n",
    "        outputs, ls,_,_ = model(img)\n",
    "        print(f'outputs.shape:{outputs.shape}')\n",
    "        print(f'ls.shape:{ls.shape}')\n",
    "        break #só quero um batch\n",
    "    ls= ls.cpu().detach().numpy()\n",
    "    labels = labels.cpu().detach().numpy()\n",
    "    return ls, labels\n",
    "\n",
    "ls, labels = test_image_clustering(model, test_dl_all)\n",
    "print(f'ls min0:{np.min(ls[0])}')\n",
    "print(f'ls max0:{np.max(ls[0])}')\n",
    "print(f'ls min1:{np.min(ls[1])}')\n",
    "print(f'ls max1:{np.max(ls[1])}')\n",
    "plot_t_test(ls,labels)\n",
    "plot2_t_test(ls,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_images(model, r0=(-5, 10), r1=(-10, 5), n=20):\n",
    "    w = 28\n",
    "    img = np.zeros((n*w, n*w))\n",
    "    for i, y in enumerate(np.linspace(*r1, n)):\n",
    "        for j, x in enumerate(np.linspace(*r0, n)):\n",
    "            z = torch.Tensor([[x, y]]).to(device)\n",
    "            x_hat = model.decoder(z)\n",
    "            x_hat = x_hat.reshape(28, 28).to('cpu').detach().numpy()\n",
    "            img[(n-1-i)*w:(n-1-i+1)*w, j*w:(j+1)*w] = x_hat\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(img, extent=[*r0, *r1])\n",
    "    \n",
    "def generate_digit(x,y):   \n",
    "    digit_size = 28\n",
    "    figure = np.zeros((digit_size, digit_size)) #matriz para n=15*28 por n=15*28\n",
    "    z = torch.Tensor([[x, y]]).to(device)\n",
    "    t_decoded = model.decoder(z)\n",
    "    digit = t_decoded[0].reshape(digit_size, digit_size).cpu().detach().numpy()\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(digit, cmap='Greys_r');    \n",
    "    \n",
    "generate_images(model,(-30,50),(-30,50))\n",
    "generate_digit(-1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
