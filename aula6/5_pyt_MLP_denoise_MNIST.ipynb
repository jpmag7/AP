{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Denoise**\n",
    "\n",
    "![image info](https://miro.medium.com/max/875/1*3zF8iZ3jaNCUlyqNOHNBSQ.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Autoencoder simples MLP para remoção de ruído em imagem utilizando o MNIST\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image_info](https://miro.medium.com/max/1400/1*kYnDIS-3yCqrIVTX8omkgQ@2x.png)\n",
    "\n",
    "\n",
    "\n",
    "![image_info](https://miro.medium.com/max/1400/0*ECdHu2yeal38Jl3P.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch mlp for binary classification\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import image\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader \n",
    "    \n",
    "from torchvision.transforms import Compose\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.utils import save_image, make_grid\n",
    "\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Constantes\n",
    "\n",
    "#path para guardar o dataset\n",
    "PATH = './'\n",
    "PATH_TRAIN = './mnist_train.csv'\n",
    "PATH_TEST = './mnist_test.csv'\n",
    "\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#device management \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "\n",
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "class DeviceDataLoader():\n",
    "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dl: \n",
    "            yield to_device(b, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches\"\"\"\n",
    "        return len(self.dl)\n",
    "\n",
    "device = get_default_device()\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Preparar os Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#buscar o dataset utilizando os CSVs e uma classe para o dataset\n",
    "\n",
    "# definição classe para o dataset\n",
    "class CSVDataset(Dataset):\n",
    "    # ler o dataset\n",
    "    def __init__(self, path_train, path_test):\n",
    "        # ler o ficheiro csv para um dataframe\n",
    "        df_train = pd.read_csv(path_train, header=0)\n",
    "        df_test = pd.read_csv(path_test, header=0)\n",
    "        # separar os inputs e os outputs\n",
    "        self.x_train = df_train.values[:, 1:]\n",
    "        xmax, xmin = self.x_train.max(), self.x_train.min()\n",
    "        self.x_train  = (self.x_train - xmin)/(xmax - xmin)\n",
    "        self.y_train = df_train.values[:, 0]\n",
    "        self.x_test = df_test.values[:, 1:]\n",
    "        xmax, xmin = self.x_test.max(), self.x_test.min()\n",
    "        self.x_test  = (self.x_test - xmin)/(xmax - xmin)\n",
    "        self.y_test = df_test.values[:, 0]\n",
    "        # garantir que os inputs e labels sejam floats\n",
    "        self.x_train = self.x_train.astype('float32')\n",
    "        self.x_test = self.x_test.astype('float32')\n",
    "        self.y_train = self.y_train.astype('long')\n",
    "        self.y_test = self.y_test.astype('long')\n",
    "   \n",
    "    # numero de casos de treino no dataset\n",
    "    def __len_train__(self):\n",
    "        return len(self.x_train)\n",
    "     # numero de casos de teste no dataset\n",
    "    def __len_test__(self):\n",
    "        return len(self.x_test)\n",
    "    \n",
    "    # retornar um caso\n",
    "    def __getitem_train__(self, idx):\n",
    "        return [self.x_train[idx], self.y_train[idx]]\n",
    "     # retornar um caso\n",
    "    def __getitem_test__(self, idx):\n",
    "        return [self.x_test[idx], self.y_test[idx]]\n",
    "    \n",
    "    # retornar indeces para casos de treino de de teste em formato flat (vetor)\n",
    "    def get_splits_flat(self):\n",
    "        x_train  = torch.from_numpy(np.array(self.x_train))\n",
    "        y_train  = torch.from_numpy(np.array(self.y_train))\n",
    "        x_test  = torch.from_numpy(np.array(self.x_test))\n",
    "        y_test  = torch.from_numpy(np.array(self.y_test))\n",
    "        train = torch.utils.data.TensorDataset(x_train,y_train)\n",
    "        test = torch.utils.data.TensorDataset(x_test,y_test)\n",
    "        return train, test \n",
    "    \n",
    "# preparar o dataset\n",
    "def prepare_data_flat(path_train, path_test):\n",
    "    # criar uma instancia do dataset\n",
    "    dataset = CSVDataset(path_train, path_test)\n",
    "    # calcular split\n",
    "    train, test = dataset.get_splits_flat()\n",
    "    # preparar data loaders\n",
    "    train_dl = DataLoader(train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    test_dl = DataLoader(test, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    train_dl_all = DataLoader(train, batch_size=len(train), shuffle=False)\n",
    "    test_dl_all = DataLoader(test, batch_size=len(test), shuffle=False)\n",
    "    return train_dl, test_dl, train_dl_all, test_dl_all\n",
    "\n",
    "# preparar os dados\n",
    "train_dl, test_dl,  train_dl_all, test_dl_all = prepare_data_flat(PATH_TRAIN, PATH_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def inject_noise(data_set, noise_factor=0.3): #introduzir ruído nas imagens\n",
    "        data_set = data_set + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=data_set.shape)\n",
    "        data_set = np.clip(data_set, 0., 1.) \n",
    "        return data_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1.1 Visualizar os Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualização das imagens\n",
    "def visualize_mnist_images_flat(dl, noise=False):\n",
    "    # get one batch of images\n",
    "    i, (inputs, targets) = next(enumerate(dl))\n",
    "    print(inputs.shape)\n",
    "    inputs = inputs.reshape(len(inputs), 1, 28, 28)\n",
    "    if noise:\n",
    "        inputs=inject_noise(inputs)\n",
    "    print(inputs.shape)\n",
    "    # plot some images\n",
    "    plt.figure(figsize=(8,8))\n",
    "    for i in range(25):\n",
    "        # define subplot\n",
    "        plt.subplot(5, 5, i+1)\n",
    "        plt.axis('off')\n",
    "        plt.grid(b=None)\n",
    "        # plot raw pixel data\n",
    "        plt.imshow(inputs[i][0], cmap='gray')\n",
    "    # show the figure\n",
    "    plt.show()\n",
    "\n",
    "visualize_mnist_images_flat(train_dl, noise=False)\n",
    "visualize_mnist_images_flat(train_dl, noise=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3. Ler o modelo previamente treinado em \"1_pyt_AE_MLP_treino_MNIST\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import models_mnist #modulo python com os modelos\n",
    "\n",
    "model = models_mnist.AE_MLP_P(x_dim=28*28, h_dim1=256, h_dim2=128, h_dim3=64, ls_dim=2)\n",
    "# ler o modelo\n",
    "SAVED_MODEL = 'AE_MLP_P_MNIST.pth'\n",
    "model= torch.load(SAVED_MODEL)\n",
    "model.eval()\n",
    "\n",
    "print(summary(model, input_size=(BATCH_SIZE,  784), verbose=0))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Usar o Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(input_imgs, input_imgs_noise, output_imgs):\n",
    "    input_imgs=input_imgs.permute((1, 2, 0))\n",
    "    input_imgs_noise=input_imgs_noise.permute((1, 2, 0))\n",
    "    output_imgs=output_imgs.permute((1, 2, 0))\n",
    "    plt.subplots(1,3, figsize=(15, 10))\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.axis('off')\n",
    "    plt.grid(b=None)\n",
    "    plt.title('Input Original')\n",
    "    plt.imshow(input_imgs, cmap='gray')\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.axis('off')\n",
    "    plt.grid(b=None)\n",
    "    plt.title('Input with Noise')\n",
    "    plt.imshow(input_imgs_noise, cmap='gray')\n",
    "    plt.subplot(1,3,3)\n",
    "    plt.axis('off')\n",
    "    plt.grid(b=None)\n",
    "    plt.title('Denoised output')\n",
    "    plt.imshow(output_imgs, cmap='gray')\n",
    "    plt.show()\n",
    "\n",
    "def test_image_reconstruction(model, test_dl):\n",
    "    for batch in test_dl:\n",
    "        img, _ = batch\n",
    "        img = img.to(device)\n",
    "        img = img.view(img.size(0), -1)\n",
    "        img_noise=inject_noise(img.cpu() )\n",
    "        img_noise = img_noise.float().to(device)\n",
    "        print(img.shape)\n",
    "        print(img_noise.shape)\n",
    "        outputs,_ = model(img_noise)\n",
    "        print(outputs.shape)\n",
    "        outputs = outputs.view(outputs.size(0), 1, 28, 28).cpu().data\n",
    "        print(outputs.shape)\n",
    "        inputs = img.view(outputs.size(0), 1, 28, 28).cpu().data\n",
    "        inputs_noise = img_noise.view(outputs.size(0), 1, 28, 28).cpu().data\n",
    "        save_image(outputs, 'mnist_reconstruction_out.png')\n",
    "        save_image(inputs, 'mnist_reconstruction_in.png')\n",
    "        outputs = make_grid(outputs)\n",
    "        inputs = make_grid(inputs)\n",
    "        inputs_noise = make_grid(inputs_noise)\n",
    "        break \n",
    "    return inputs, inputs_noise, outputs\n",
    "\n",
    "inputs, inputs_noise, outputs = test_image_reconstruction(model, test_dl)\n",
    "visualize(inputs, inputs_noise, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fazer uma previsão utilizando um caso\n",
    "def make_prediction(model, img_list, idx):\n",
    "    print(img_list.shape)\n",
    "    print(img_list.dtype) \n",
    "    img_list = img_list.to(device)\n",
    "    img_list_noise=inject_noise(img_list.cpu() )\n",
    "    img_list_noise = img_list_noise.float().to(device)    \n",
    "    prediction,_ = model(img_list_noise)\n",
    "    print(prediction.shape)\n",
    "    prediction = prediction.view(prediction.size(0), 1, 28, 28).cpu().data\n",
    "    print(prediction.shape)\n",
    "    img = img_list[idx].reshape(1,28, 28).cpu()\n",
    "    img_noise = img_list_noise[idx].reshape(1,28, 28).cpu()\n",
    "    plt.subplots(1,3, figsize=(15, 10))\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.axis('off')\n",
    "    plt.grid(b=None)\n",
    "    plt.title('Input Original')\n",
    "    plt.imshow(img.permute((1, 2, 0)), cmap='gray')\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.axis('off')\n",
    "    plt.grid(b=None)\n",
    "    plt.title('Input with Noise')\n",
    "    plt.imshow(img_noise.permute((1, 2, 0)), cmap='gray')\n",
    "    plt.subplot(1,3,3)\n",
    "    plt.axis('off')\n",
    "    plt.grid(b=None)\n",
    "    plt.title('Denoised output')\n",
    "    plt.imshow(prediction[idx].permute((1, 2, 0)), cmap='gray')\n",
    "    plt.show()\n",
    "\n",
    "_, (inputs, targets) = next(enumerate(test_dl))\n",
    "make_prediction(model,inputs, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
