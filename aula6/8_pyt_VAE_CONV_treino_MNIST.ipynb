{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Variational Autoencoder simples com convoluções utilizando o MNIST\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image_info](https://i.stack.imgur.com/knXYA.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch mlp for binary classification\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#from matplotlib import image\n",
    "import time\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import Sequential\n",
    "from torch.nn import Linear\n",
    "from torch.nn import Conv2d\n",
    "from torch.nn import MaxPool2d\n",
    "from torch.nn import BatchNorm1d\n",
    "from torch.nn import BatchNorm2d\n",
    "from torch.nn import ConvTranspose2d\n",
    "from torch.nn import ReLU\n",
    "from torch.nn import Softmax, Tanh, Sigmoid\n",
    "from torch.nn import Module\n",
    "from torch.nn import MSELoss\n",
    "from torch.nn import BCELoss, BCEWithLogitsLoss\n",
    "from torch.nn.init import kaiming_uniform_\n",
    "from torch.nn.init import xavier_uniform_\n",
    "from torch.optim import SGD, Adam, RMSprop \n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "from torchvision.transforms import Compose\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.utils import save_image, make_grid\n",
    "\n",
    "#pip install torchinfo\n",
    "from torchinfo import summary\n",
    "from livelossplot import PlotLosses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Constants\n",
    "\n",
    "#path para guardar o dataset\n",
    "PATH = './'\n",
    "PATH_TRAIN = './mnist_train.csv'\n",
    "PATH_TEST = './mnist_test.csv'\n",
    "\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#device management \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "\n",
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "class DeviceDataLoader():\n",
    "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dl: \n",
    "            yield to_device(b, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches\"\"\"\n",
    "        return len(self.dl)\n",
    "\n",
    "device = get_default_device()\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Preparar os Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#buscar o dataset utilizando os CSVs e uma classe para o dataset\n",
    "\n",
    "# definição classe para o dataset\n",
    "class CSVDataset(Dataset):\n",
    "    # ler o dataset\n",
    "    def __init__(self, path_train, path_test):\n",
    "        # ler o ficheiro csv para um dataframe\n",
    "        df_train = pd.read_csv(path_train, header=0)\n",
    "        df_test = pd.read_csv(path_test, header=0)\n",
    "        # separar os inputs e os outputs\n",
    "        self.x_train = df_train.values[:, 1:]\n",
    "        self.x_train = self.x_train.reshape(len(self.x_train), 1, 28, 28)\n",
    "        xmax, xmin = self.x_train.max(), self.x_train.min()\n",
    "        self.x_train  = (self.x_train - xmin)/(xmax - xmin)\n",
    "        self.y_train = df_train.values[:, 0]\n",
    "        self.x_test = df_test.values[:, 1:]\n",
    "        self.x_test = self.x_test.reshape(len(self.x_test), 1, 28, 28)\n",
    "        xmax, xmin = self.x_test.max(), self.x_test.min()\n",
    "        self.x_test  = (self.x_test - xmin)/(xmax - xmin)\n",
    "        self.y_test = df_test.values[:, 0]\n",
    "        # garantir que os inputs e labels sejam floats\n",
    "        self.x_train = self.x_train.astype('float32')\n",
    "        self.x_test = self.x_test.astype('float32')\n",
    "        self.y_train = self.y_train.astype('long')\n",
    "        self.y_test = self.y_test.astype('long')\n",
    "        \n",
    "    # numero de casos de treino no dataset\n",
    "    def __len_train__(self):\n",
    "        return len(self.x_train)\n",
    "     # numero de casos de teste no dataset\n",
    "    def __len_test__(self):\n",
    "        return len(self.x_test)\n",
    "    \n",
    "    # retornar um caso\n",
    "    def __getitem_train__(self, idx):\n",
    "        return [self.x_train[idx], self.y_train[idx]]\n",
    "     # retornar um caso\n",
    "    def __getitem_test__(self, idx):\n",
    "        return [self.x_test[idx], self.y_test[idx]]\n",
    "    \n",
    "    # retornar indeces para casos de treino de de teste em formato flat (vetor)\n",
    "    def get_splits(self):\n",
    "        x_train  = torch.from_numpy(np.array(self.x_train))\n",
    "        y_train  = torch.from_numpy(np.array(self.y_train))\n",
    "        x_test  = torch.from_numpy(np.array(self.x_test))\n",
    "        y_test  = torch.from_numpy(np.array(self.y_test))\n",
    "        train = torch.utils.data.TensorDataset(x_train,y_train)\n",
    "        test = torch.utils.data.TensorDataset(x_test,y_test)\n",
    "        return train, test \n",
    "\n",
    "# preparar o dataset\n",
    "def prepare_data_flat(path_train, path_test):\n",
    "    # criar uma instancia do dataset\n",
    "    dataset = CSVDataset(path_train, path_test)\n",
    "    # calcular split\n",
    "    train, test = dataset.get_splits()\n",
    "    # preparar data loaders\n",
    "    train_dl = DataLoader(train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    test_dl = DataLoader(test, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    train_dl_all = DataLoader(train, batch_size=len(train), shuffle=False)\n",
    "    test_dl_all = DataLoader(test, batch_size=len(test), shuffle=False)\n",
    "    return train_dl, test_dl, train_dl_all, test_dl_all\n",
    "\n",
    "# preparar os dados\n",
    "train_dl, test_dl,  train_dl_all, test_dl_all = prepare_data_flat(PATH_TRAIN, PATH_TEST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1.1 Visualizar os Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualização das imagens\n",
    "def visualize_mnist_images_flat(dl):\n",
    "    # get one batch of images\n",
    "    i, (inputs, targets) = next(enumerate(dl))\n",
    "    print(inputs.shape)\n",
    "    # plot some images\n",
    "    plt.figure(figsize=(8,8))\n",
    "    for i in range(25):\n",
    "        # define subplot\n",
    "        plt.subplot(5, 5, i+1)\n",
    "        plt.axis('off')\n",
    "        plt.grid(b=None)\n",
    "        # plot raw pixel data\n",
    "        plt.imshow(inputs[i][0], cmap='gray')\n",
    "    # show the figure\n",
    "    plt.show()\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. Definir o Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import models_mnist #modulo python com os modelos    \n",
    "\n",
    "model = models_mnist....\n",
    "#visualizar a rede\n",
    "print(summary(model, input_size=(BATCH_SIZE,  1,28,28), verbose=0))\n",
    "#model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3. Treinar o Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# treino do modelo\n",
    "def train_model(h5_file,train_dl, test_dl, model, loss_function, optimizer, scheduler, epochs):\n",
    "    liveloss = PlotLosses() \n",
    "    for epoch in range(epochs):\n",
    "        logs = {} \n",
    "        model.train()\n",
    "        running_loss  = 0.0 \n",
    "        for inputs, _ in train_dl: \n",
    "            inputs = inputs.to(device)\n",
    "            outputs, mu, log_var, _ = model(inputs)\n",
    "            loss = loss_function(outputs, inputs, mu, log_var)\n",
    "            optimizer.zero_grad() \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        epoch_loss = running_loss / len(train_dl.dataset)\n",
    "        logs['loss'] = epoch_loss*1000       \n",
    "        #Validation phase\n",
    "        model.eval()\n",
    "        running_loss  = 0.0\n",
    "        for inputs, _ in test_dl: \n",
    "            inputs = inputs.to(device)\n",
    "            outputs, mu, log_var, _ = model(inputs)\n",
    "            loss = loss_function(outputs, inputs, mu, log_var)\n",
    "            running_loss += loss.item()\n",
    "        epoch_loss = running_loss / len(test_dl.dataset)\n",
    "        logs['val_loss'] = epoch_loss*1000\n",
    "        scheduler.step(epoch_loss) #callback a meio para atualizar lr\n",
    "        epoch_lr = optimizer.param_groups[0]['lr'] \n",
    "        logs['val_lr'] = epoch_lr \n",
    "        liveloss.update(logs) #para visualizarmos o processo de treino\n",
    "        liveloss.send() #para visualizarmos o processo de treino\n",
    "    torch.save(model,h5_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# treinar o modelo\n",
    "import torch.nn.functional as F\n",
    "EPOCHS = 30\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "# return reconstruction error + KL divergence losses\n",
    "def loss_function(recon_x, x, mu, log_var):\n",
    "    BCE = F.binary_cross_entropy(recon_x, x, reduction='sum')\n",
    "    KLD = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "    return BCE + KLD\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', factor=0.1, patience=5)\n",
    "starttime = time.perf_counter()\n",
    "train_model('VAE_CONV_MNIST.pth', train_dl, test_dl, model, loss_function, optimizer, scheduler, EPOCHS)\n",
    "endtime = time.perf_counter()\n",
    "print(f\"Tempo gasto: {endtime - starttime} segundos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Usar o Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def visualize(input_imgs, output_imgs):\n",
    "    input_imgs=input_imgs.permute((1, 2, 0))\n",
    "    output_imgs=output_imgs.permute((1, 2, 0))\n",
    "    plt.subplots(1,2, figsize=(10, 10))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.axis('off')\n",
    "    plt.grid(b=None)\n",
    "    plt.title('Autoencoder Input')\n",
    "    plt.imshow(input_imgs, cmap='gray')\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.axis('off')\n",
    "    plt.grid(b=None)\n",
    "    plt.title('Autoencoder Output')\n",
    "    plt.imshow(output_imgs, cmap='gray')\n",
    "    plt.show()\n",
    "\n",
    "def test_image_reconstruction(model, test_dl):\n",
    "    for batch in test_dl:\n",
    "        img, _ = batch\n",
    "        img = img.to(device)\n",
    "        print(img.shape)\n",
    "        outputs,_,_,_ = model(img)\n",
    "        print(outputs.shape)\n",
    "        outputs = outputs.view(outputs.size(0), 1, 28, 28).cpu().data\n",
    "        print(outputs.shape)\n",
    "        inputs = img.view(outputs.size(0), 1, 28, 28).cpu().data\n",
    "        outputs = make_grid(outputs)\n",
    "        inputs = make_grid(inputs)\n",
    "        break \n",
    "    return inputs, outputs\n",
    "\n",
    "model= torch.load(..., map_location ='cpu')\n",
    "inputs, outputs = test_image_reconstruction(model, train_dl)\n",
    "visualize(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fazer uma previsão utilizando um caso\n",
    "def make_prediction(model, img_list, idx):\n",
    "    print(img_list.shape)\n",
    "    print(img_list.dtype) \n",
    "    img_list = img_list.to(device)  \n",
    "    prediction,_,_,_ = model(img_list)\n",
    "    print(prediction.shape)\n",
    "    prediction = prediction.view(prediction.size(0), 1, 28, 28).cpu().data\n",
    "    print(prediction.shape)\n",
    "    img = img_list[idx].reshape(1,28, 28).cpu()\n",
    "    plt.subplots(1,2, figsize=(10, 10))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.axis('off')\n",
    "    plt.grid(b=None)\n",
    "    plt.title('Imagem Input')\n",
    "    plt.imshow(img.permute((1, 2, 0)), cmap='gray')\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.axis('off')\n",
    "    plt.grid(b=None)\n",
    "    plt.title('Imagem Output')\n",
    "    plt.imshow(prediction[idx].permute((1, 2, 0)), cmap='gray')\n",
    "    plt.show()\n",
    "    \n",
    "_, (inputs, targets) = next(enumerate(test_dl))\n",
    "make_prediction(model,inputs, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
